\documentclass{llncs}
%DB: presume this is the correct class

\usepackage{amsfonts}
\usepackage[dvipsnames]{xcolor}
\newenvironment{structure}{
  \begin{color}{ForestGreen}
}{
  \end{color}
}

\newcommand{\alg}[1]{\textup{\texttt{#1}}}

\begin{document}

\section{Introduction}

\begin{structure}
Outline target audience, presentation strategy (incremental requirements based on attacks), gap we fill, our emphasis on rigourous models
\end{structure}

This chapter aims to present voting from a cryptographer's point of view. We
will state some security properties that one could desire of a voting scheme and
present methods to achieve these properties using cryptography. 

\section{First steps}

\begin{structure}
motivating example, realisation (envelopes), security/trust models;
primitives required for crypto implementation, FOO
\end{structure}

\subsection{Example}

Here is one way to run a poll. Voters enter a polling station and pick up a voting card on which the candidates standing for election or choices in a referendum are printed. They fill in their card by placing crosses in boxes. Then they take their card and put it in an opaque envelope which they seal. In keeping with the cryptographic constructions we will describe later, we call such an envelope containing a filled in vote card a ``ballot''. This completes the first step, ballot creation.

To cast their ballots, voters present them to an official along with some identification. The official checks that the voter is registered at this polling station and has not cast a vote yet, but the official does not get to see the vote itself. Then the official places the ballot-envelope in a stamping machine and stamps the envelope, in such a way that the imprint of the stamp is not only visible on the envelope but also transferred to the vote card within.

Voters post their ballots to a counting centre. The postal service agrees to send any correctly stamped envelope free of charge from anywhere in the country so voters can post their envelope anonymously in any post box that they choose. 
The counting centre shuffles all received envelopes again, opens them and counts all vote cards that contain an imprint of the official stamp.

\subsection{Thinking about security}

\subsection{Cryptographic primitives}

\begin{structure}
\begin{itemize}
\item digital signatures
\item blind signatures
\item commitments
\end{itemize}
\end{structure}

\subsubsection{Digital signatures.}

% DB: This is a new section (nothing to copy across like for encryption/PoKs) so
% I'll try making a first attempt at writing something for it now.

Digital signatures are the cryptographer's replacement for signatures or stamps.
If we know what someone's signature looks like and believe that it would be hard
for anyone but the owner to produce such a signature, the presence of such a
signature on a document attests that the owner has seen and signed it.
Similarly, the imprint of a stamp on a document attests that someone with the
appropriate stamp has seen the document.

Digital signatures differ from phyiscal ones in that they are not placed on an
original document, modifying the original, but are separate objects that can be
provided alongside the original. As a consequence, to prevent someone from
transferring a signature from one document to another, digital signatures for
different documents will be completely different objects.

To be able to create digital signatures, a signer first has to generate a pair
of keys called the signing key (or secret key) and verification key (or public
key). To do this, a digital signature scheme defines a key generation algorithm.
The signing key is like a stamp with which the signer can stamp documents. Such
a stamp on a document does not mean much on its own (anyone can create their own
stamps) but if you know what a particular person's or organisation's stamp looks
like, you can verify any stamped document to see if it was really stamped by the
person or organisation you know, by comparing the imprint on the document with
the imprint you know to be theirs. The verification key plays a similar role for
digital signatures.

A digital signature scheme comes with two more algorithms. The signing algorithm
takes a document and a signing key as input and returns a signature for the
document. The verification algorithm takes a document, a signature and a
verification key and outputs 1 if the signature is valid for the given key and
document, otherwise 0.

It is the signer's responsibility that all verifiers have an authentic copy of
the verification key. For example, in some government e-ID card schemes every
citizen gets a smartcard containing a signing key and the government maintains a
public database of verification keys. For a digital election, if the election
authorities need to sign ballots they can publish their verification key as part
of the election specification.

\begin{definition}
A digital signature scheme $\Sigma$ is a triple of algorithms
\[
\Sigma = \left( \alg{KeyGen}, \alg{Sign}, \alg{Verify} \right)
\]
known as the key generation, signing and verification algorithms and satisfying
the correctness condition below.

The key generation algorithm takes no input and produces a pair of keys $(sk,
vk) \gets \alg{KeyGen}()$ known as the signing and verification keys. The siging
algorithm takes a signing key $sk$ and a message $m$ as inputs and produces a
signature $\sigma \gets \alg{Sign}(sk, m)$. The verification algorithm must be
deterministic. It takes a verification key $vk$, a message $m$ and a signature
$\sigma$ as inputs and returns $0$ or $1$. We say that $\sigma$ is a (valid)
signature for $m$ under key $vk$ if $\alg{Verify}(vk, m, \sigma) = 1$.

A digital signature scheme must satisfy the following correctness condition
which means that correctly generated signatures are always valid. For any
message $m$, if you run the following sequence of algorithms then you get $b =
1$:
\[
(sk, vk) \gets \alg{KeyGen}();\ \sigma \gets \alg{Sign}(sk, m);\ b \gets \alg{Verify}(vk, m, \sigma)
\]
\end{definition}

This definition tells you what a digital signature scheme is and how to use it
but does not yet say anything about security. It is common in cryptography to
define a class of schemes in two parts, keeping functionality and security
separate. This has many advantages including that we can reason about several
different levels of security for the same class of schemes.

\subsubsection{Security models.}
We introduce the cryptographer's viewpoint of security using digital signatures
as an example. Security means that an attacker can not do certaing things, like
create a signature on a document that verifies under someone else's key. To
formalise this, it is common to define a cryptographic game which captures
exactly what we want an attacker not to be able to do. The security definition
is then the claim that no attacker can win the given game.

Security games can be defined in three parts. First, the game begins with some
setup algorithm. Secondly, we give one or more moves that the attacker can play
in the game. Finally, we state the winning conditions for the attacker.

\subsubsection{Security of digital signatures.}
An obvious property that signatures should have is that you cannot forges a
signature on a message that verifies under someone else's key. We call such a
forgery an existential forgery and we call an attacker that produces such a
forgery a no-message attacker (we will see why in a moment). The security game
and notion for this property have the game create a key pair and give the
adversary the verification key, which is supposed to be public. The adversary
wins if she produces a forgery:

\begin{definition}
A digital signature scheme is existentially unforgeable under no-message attacks
(EF-NMA) if no attacker can win the following game.

    \begin{description}
    \item[Setup] The game creates a key pair $(sk, vk) \gets \alg{KeyGen}()$ and
                 saves them; the attacker gets the verification key $vk$.

    \item[Moves] None in this game.

    \item[Winning conditions] The attacker wins the game if she provides a
    message/ signature pair $(m^*, sk^*)$ such that this pair verifies under the
    game's key: $\alg{Verify}(vk, m^*, \sigma^*) = 1$.
    \end{description}
\end{definition}

This definition is considered necessary but not sufficient. The attacker may be
a participant in some system using digital signatures in which she gets to see
messages legitimately signed by some other person; she should still not be able
to forge anyone else's signature on any message they did not sign. This includes
such attacks as taking a signature off one message and claiming that the signer
actually signed some other message. Cryptographers model this with the chosen-
message attack game. Here the adversary gets an extra move: she may ask the game
to sign any messages of her choice and wins if she can forge a signature on any
message that the game did not sign.

\begin{definition}
A digital signature scheme is existentially unforgeable under chosen message
attacks (EF-CMA) if no attacker can win the following game.

\begin{description}
\item[Setup] The game creates a key pair $(sk, vk) \gets \alg{KeyGen}()$ and
saves them; the attacker gets the verification key $vk$. The game also makes an
empty list $L$ of signed messages.

\item[Moves] The attacker may, any number of times, send the game a message $m$
of her choice. The game signs this message producing a signature $\sigma \gets
\alg{Sign}(sk, m)$, adds $m$ to $L$ and returns $\sigma$ to the attacker.

\item[Winning conditions] The attacker wins the game if she provides a message/
signature pair $(m^*, sk^*)$ such that (1) this pair verifies under the game's
key: $\alg{Verify}(vk, m^*, \sigma^*) = 1$ and (2) the game never signed the
message $m^*$, i.e. $m^* \notin L$.
\end{description}
\end{definition}

In neither of the above games would it make any difference if we gave the
attacker an extra move to verify signatures: she already knows the verification
key $vk$ so she can do this herself.

\textcolor{blue}{DB: do UF-CMA too?}

\subsubsection{Blind signatures.}
Voting is one of several applications where it is useful to be able to sign
messages without knowing their content. To ensure that only authorized voters
cast ballots, one could ask voters to authenticate themselves with an authority
who holds a signing key and signs the ballots of authorized voters.
Unfortunately, a straightforward use of digital signatures here would reveal
everyone's votes to the authority. Instead, one can use blind signatures: each
voter fills in her ballot and blinds it, then authenticates herself to the
authority that signs the blinded ballot without knowing its contents. The voter
then turns the signature on the blinded ballot into a signature on the real
ballot and casts this ballot along with the signature.

Blind signatures will require two security properties. Security for the signer
requires that no-one can forge signatures on messages that the signer has not
blind-signed, even though the signer will not usually know which messages she
has signed. Security for the user (in our case, the voter) requires that the
signer cannot learn which messages she has signed. We follow Schr\"oder and
Unruh \cite{US11} in the definition of security properties.

\begin{definition}
A blind signature scheme $BS$ is a tuple of algorithms
\[
BS = \left(
\alg{KeyGen}, \alg{User}, \alg{Signer}, \alg{Verify}
\right)
\]
The key generation algorithm takes no input and returns a pair of keys $(sk, vk)
\gets \alg{KeyGen}$ called the signing and verification keys. \alg{User} and
\alg{Signer} are a pair of interactive algorithms. The user algorithm takes a
message $m$ as input, the signer algorithm takes a signing key $sk$ as input.
When these two algorithms interact, the user gets a signature $\sigma \gets
[\alg{User}(m), \alg{Signer}(sk)]$ and the signer gets no output.
The verification algorithm is determinstic and takes a verification key, message
and signature as input and outputs 0 or 1. We call a signature $\sigma$ valid
for message $m$ and key $vk$ if $\alg{Verify}(vk, m, \sigma) = 1$.

A blind signature scheme $BS$ must have the following correctness property: for
any message $m$, running
\[
(sk, vk) \gets \alg{KeyGen}();\ \sigma \gets [\alg{User}(m), \alg{Signer}(sk)];\ 
b \gets \alg{Verify}(vk, m, \sigma)
\]
returns $b = 1$.
\end{definition}

\begin{definition}
A blind signature scheme is unforgeable (secure for the signer) if no attacker
can win the following game.

\begin{description}
\item[Setup] The game creates a key pair $(sk, vk) \gets \alg{KeyGen}$ and saves
them. It also creates a list $L$ of signed messages which starts out empty. The
attacker gets $vk$.

\item[Moves] The attacker may submit a message $m$ for signing as long as
$m \notin L$. The game runs $\sigma \gets [\alg{User}(m), \alg{Signer}(sk)]$,
adds $m$ to $L$ and returns the signature $\sigma$. The attacker may use this
move as many times as she likes.

\item[Winning conditions] The attacker wins if she can output a list of message/
signature pairs
\[
((m_1, \sigma_1), (m_2, \sigma_2), \ldots, (m_{k+1}, \sigma_{k+1}))
\]
satisfying the following conditions: (1) all messages are distinct: $m_i \neq m_j$
for all pairs $(i, j)$ with $i \neq j$ (2) all pairs verify i.e.
$\alg{Verify}(vk, m_i, \sigma_i) = 1$ for all $i$ and
(3) the attacker has made at most $k$ signature moves, i.e. fewer than the number
of messages she returns.
\end{description}
\end{definition}

The list $L$ here serves a slightly different purpose than for plain digital
signatures: it prevents the attacker from submitting the same message twice. The
winning condition is that the attacker has produced signatures on more messages
than she has used in signing moves, so at least one of her output pairs is a
genuine forgery. The reason for this formulation is that some blind signature
schemes allow you to take a message signature pair $(m, \sigma)$ and create a
new signature $\sigma' \neq \sigma$ on the same message such that $(m, \sigma')$
is still a valid message/signature pair on the same key.

The definition of blindness is a so-called indistinguishability game. Here, an
attacker's success cannot be measured in a single experiment but only as the
probability that an attacker is successful on average. The game will start by
picking a bit $b$ and will act differently depending on the bit. The attacker's
aim is to guess the bit $b$ and the security definition says that the attacker
cannot do better than guess at random.

In the blindness game, the attacker takes the role of the signer. She may
interact with two users bringing messages of the attacker's choice to be signed;
her aim is to guess which order the users come in.

\begin{definition}
A blind signature scheme is blind (secure for the user) if no attacker can guess
the bit $b$ in the following game with better probability than one half.

\begin{description}
\item[Setup]
The game picks a bit $b$ at random from the set $\{0, 1\}$.

\item[Moves]
The attacker has only one move and she may use it only once. First, the attacker
may send the game a verification key $vk$. The attacker may then choose a pair
of messages $(m_0, m_1)$ and send them to the game. The game starts two user
processes, the first one for $m_b$ and the second one for $m_{1-b}$, both of
which interact with the attacker (who takes the role of signer, but may do
anything she likes). If this results in both users getting a valid signature,
the attacker gets the signatures $(\sigma_0, \sigma_1)$ on $m_0$ and $m_1$
respectively.

\item[Winning conditions]
The adversary may make a guess for $b$ at any time. This stops the game.
The adversary wins if the guess is correct.
\end{description}
\end{definition}

\subsubsection{Explicit form of blind signatures.}
The above definition of blind signatures applies to many different schemes.
Some of these schemes have a more explicit form however that is easier to work
with in cryptographic proofs. We follow the presentation of Fujoka et al. \cite{FOO92} since we are working towards their voting protocol; a blind signature scheme that has an explicit form is for example the one of Chaum \cite{C85}.

\begin{definition}
A blind signature scheme in explicit form is a tuple
\[
BS = \left( \alg{KeyGen}, \alg{Blind}, \alg{Sign}, \alg{Unblind}, \alg{Verify} \right)
\]
of algorithms where \alg{Verify} is deterministic and the rest may be
randomized. The key generation algorithm outputs a keypair $(sk, vk) \gets
\alg{KeyGen}()$. The blinding algorithm takes a message $m$ and a verification
key $vk$ and outputs a blinded message $b$ and an unblinding factor $u$: $(b, u)
\gets \alg{Blind}(m, vk)$. The signing algorithm takes a signing key $sk$ and a
blinded message $b$ and outputs a blinded signature $s \gets \alg{Sign}(b, sk)$.
The unblinding algorithm takes a verification key $vk$, a blinded signature $s$
and an unblinding factor $u$ and outputs a signature $\sigma \gets
\alg{Unblind}(vk, s, u)$. The verification algorithm finally takes a
verification key $vk$, a message $m$ and a signature $\sigma$ and outputs a bit
$v \gets \alg{Verify}(vk, m, \sigma)$ that is 1 if the signature verifies.

A blind singature scheme in explicit form is correct if the following outputs $v
= 1$ for any message $m$, i.e. a correctly generated signature verifies:
\[
\begin{array}{l}
(sk, vk) \gets \alg{KeyGen}();\ 
(b, u) \gets \alg{Blind}(vk, m);\ 
s \gets \alg{Sign}(sk, b);\ \\
\sigma \gets \alg{Unblind}(vk, s, u);\ 
v \gets \alg{Verify}(vk, m, \sigma)
\end{array}
\]
\end{definition}

From the explicit form we can reconstruct the signer and user algorithms: the
signer algorithm receives a blinded message from the user, applies $\alg{Sign}$
with the signing key $sk$ and sends the result back to the user. The user
algorithm applies \alg{Blind} to the message, saves the unblinding factor $u$
and sends the blinded message $b$ to the signer; when the user algorithm gets a
value $s$ back from the signer it applies \alg{Unblind} using the saved factor
$u$ and outputs the resulting blind signature (to its caller, not the signer).

From this observation we could derive explicit forms of the the security games
for blind signatures in explicit form and check that the correctness conditions
in the two cases match up. The other way round is not possible in general as not
all blind signature schemes have an explicit form the way we defined it.

We now turn our attention to a possible implementation of standard and blind
digital signatures based on the famous RSA construction.

\subsubsection{RSA.}
In 1978, Rivest, Shamir and Adleman constructed the first public-key encryption
scheme \cite{RSA78}. In 1985, Chaum used RSA to propose and construct a blind
signature scheme which we will present in the next section; let us first
describe the RSA construction.

Pick two prime numbers $p, q$ and multiply them together to get $N = pq$. The
RSA construction lives in the ring $\mathbb Z^*_N$: the elements are the
integers $\{1, 2, \ldots, N-1\}$ with the operation of multiplication modulo
$N$. This ring is not a field ($p$, $q$ are zero-divisors after all) but for
large $N$, if we pick a random element $x$ from $\{1, \ldots, N-1\}$ the chance
of hitting a non-invertible element is small. One idea behind RSA is that if you
know $N$ but not $p$ and $q$, you can treat $\mathbb Z^*_N$ as if it were a
field. Specifically, you can try and invert any element with Euclid's algorithm
and if you find a non-invertible element then you can factor $N$ (you've found a
multiple of $p$ or $q$ that's coprime to the other factor of $N$) and vice
versa. Factoring is arguably the most famous computationally hard problem in
mathematics; lots of research has gone into number-theoretic siveing algorithms
to aid in factoring large numbers and the current record for a number $N$ of the
kind used in RSA is the number 
\[\begin{array}{rl}
\textrm{RSA-768} = & 
12301866845301177551304949583849627207728535695953 \\ &
34792197322452151726400507263657518745202199786469 \\ &
38995647494277406384592519255732630345373154826850 \\ &
79170261221429134616704292143116022212404792747377 \\ &
94080665351419597459856902143413 \\
\end{array}\]
which has 768 bits when written in binary and was factored in December 2009.
Current RSA key length recommendations\footnotemark are to use keys of at least
1024 bits if not 2048.
\footnotetext{In practice there are further restrictions on the type of $p$ and
$q$ you must choose, such that $(p-1)/2$ and $(q-1)/2$ should also be prime to
avoid particular number-theoretic factoring tricks; we will not go into details
of these matters here.}

If you pick an element $x \in \mathbb Z^*_N$ coprime to $N$ (not a multiple of
$p$ or $q$) and look at the subgroup $\{x^k \pmod{N} \mid k \in \mathbb N\}$
that it generates then this subgroup has order exactly $(p-1)(q-1)$, i.e.
$x^{(p-1)(q-1)} = 1 \pmod{N}$. The RSA construction makes use of exponentiation
modulo $N$ as its basic operation. The idea is that if you pick a pair of
integers $e, d$ satisfying $e \cdot d = 1 \pmod{(p-1)(q-1)}$ then for any
invertible $x \in \mathbb Z^*_N$ the equation $(x^e)^d = x^{e \cdot d} = x
\pmod{N}$ holds, i.e. exponentiating with $e$ and $d$ are mutually inverse
operations. Crucially, given $N$ and any $e$ that is coprime to $N$, it is
considered hard to find the corresponding $d$ or to compute $x^d \pmod{N}$ for
random $x$. A cryptographer would say that $x \mapsto x^e \pmod{N}$ is a
trapdoor one-way function: one-way because it is easy to compute yet hard to
invert; ``trapdoor'' because given $d$ it becomes easy to invert. Upon such a
function one can construct much of modern cryptography.
While it is clear that if you can factor $N$ you can also find the $d$ value
for any $e$, the other direction is less clear. However, RSA has stood the test
of time in that no-one has managed to attack properly generated RSA keys of
decent key sizes, either through factoring or any other means, since the system
was first proposed.

\textcolor{Fuchsia}{Is this correct?}

To generate an RSA keypair (whether for encryption, signing or many other
applications), the key generation algorithm \alg{KeyGen} performs the following
steps:
\begin{enumerate}
\item Pick large enough primes $p$ and $q$ and compute $N = pq$. The bitlength
of $N$ is your key length.
\item Pick any unit $e$ of $\mathbb Z^*_N$ --- choices such as $e = 3$ or $e =
2^{16}+1$ are common as they are efficient to work with.
\item Find $d$ such that $ed = 1 \pmod{(p-1)(q-1)}$ (since you know $p, q$ this
can be done with a variation on Euclid's algorithm).
\item Your public key is the pair $(N, e)$. People can share $e$ but everyone
gets their own $N$. Your private key is the tuple $(N, e, d, p, q)$ --- most of
the time, the pair $(N, d)$ suffices to work with though.
\end{enumerate}

\textcolor{Fuchsia}{Is $2^{16}+1$ the common $e$? CHECK.}

\subsubsection{RSA signatures and blind signatures.}
To sign a message $m \in \mathbb Z^*_N$ (without blinding) with a RSA private
key $(N, d)$ and public key $(N, e)$, you compute
\[
\alg{Sign}((N, d), m) := m^d \pmod{N}
\]
and to verify a signature $\sigma$, check that the following returns $1$:
\[
\alg{Verify}((N, e), m, \sigma) :=
\left\{ \begin{array}{lll}
1, & \textrm{if} & \sigma^e = m \pmod{N} \\
0, & \textrm{otherwise} & \\
\end{array} \right.
\]

Chaum's blind signature has the user blind the message $m$ with a random value
$r$ before sending it to the signer and strip this factor out again afterwards:

\begin{description}
\item[\alg{KeyGen}:] Standard RSA key generation.
\item[\alg{Blind}$((N, e), m)$:] pick a random $r$ from $\mathbb Z^*_N$ and set
$b := m \cdot r^e \pmod{N}$, $u := r$.
\item[\alg{Sign}:] as for the basic RSA signature.
\item[\alg{Unblind}$((N, e), s, u)$:] Compute $\sigma := s/u \pmod{N}$.
\item[\alg{Verify}:] as for the basic RSA signature.
\end{description}

Let us check correctness of the blind signature. We have
\[
\sigma^e = (s/u)^e = ((m \cdot r^e)^d)^e = m^{e \cdot d} (r^{e \cdot d})^e =
1 \cdot 1^e = 1 \pmod{N}
\]
Note that $\sigma$ is exactly the standard RSA signature on $m$ for verfication
key $(N, e)$.

\subsubsection{Commitment schemes.}
A commitment scheme is the cryptographer's equivalent of placing a message in an
opaque envelope and placing this envelope on the table: no-one else can can read
your message until you open the envelope but you cannot change the message that
you have placed in the envelope either: you are committed to the message.

\begin{definition}
A commitment scheme $CS$ is a pair of algorithms
\[
CS = \left( \alg{Commit}, \alg{Open}\right)
\]
called the commitment and opening algorithm. The commitment algorithm takes a
message $m$ and returns a commitment $c$ and an opening key $k$: $(c, k) \gets
\alg{Commit}(m)$. The opening algorithm takes a message $m$, a commitment $c$
and a key $k$ and returns a bit $b$ to indicate whether the commitment matches
the message: $b \gets \alg{Open}(m, c, k)$. The opening algorithm must be
deterministic.

A commitment scheme must satisfy the following correctness property. For any
message $m$, if you run
\[
(c, k) \gets \alg{Commit}(m);\ b \gets \alg{Open}(m, c, k)
\]
then $b = 1$ i.e. correctly commited messages also open correctly.
\end{definition}

Security of commitment schemes has two parts. A commitment is hiding if you
cannot extract a committed message from a commitment until it is opened. A
commitment is binding if you cannot change it once committed.

In more detail, the hiding property says that for any two messages of your
choice, if you are given a commitment to one of them then you cannot guess
better than at random which message was committed to.

\begin{definition}
A commitment scheme $CS = (\alg{Commit}, \alg{Open})$ is hiding if no attacker
can win the following game with better probability than one half. If we consider
attackers with unbounded computation power, we can call a scheme perfectly
hiding; for attackers with reasonable (polynomially bounded) power we can call a
scheme computationally hiding.

\begin{description}
\item[Setup]
The game picks a bit $b$ at random.

\item[Moves]
The attacker may, once only, send a pair of messages $m_0, m_1$. The game runs
$(c, k) \gets \alg{Commit}(m_b)$ and returns $c$ to the attacker.

\item[Winning conditions]
The attacker wins if she guesses $b$. A guess stops the game.
\end{description}
\end{definition}

The binding property asks the attacker to produce one commitment $c$ and two
different messages $m, m'$ to which she can open the commitment, i.e. keys
$k, k'$ (which may or may not be the same) such that \alg{Open} returns 1 on
both triples involved.

\begin{definition}
A commitment scheme $CS = (\alg{Commit}, \alg{Open})$ is binding if no attacker
can win the following game. The same specialisation into perfectly and
computationally binding applies as for the hiding property.

\begin{description}
\item[Setup]
No setup.

\item[Moves]
No moves.

\item[Winning conditions]
The attacker may provide a string $c$, two messages $m, m'$ and two keys
$k, k'$. She wins if (1) $m \neq m'$ and (2) both $\alg{Open}(c, m, k)$ and
$\alg{Open}(c, m', k')$ return 1.
\end{description}
\end{definition}

\subsection{The FOO protocol}

The cryptographic tools we introduced above allow us to give the voting scheme
presented by Fujioka, Okamoto and Ohta at Auscrypt 1992 \cite{FOO92}. This
scheme was also the one that we motivated in the informal example above and has
the convenient abbreviation FOO.

The FOO protocol uses two administrators, a counter who publishes all ballots
sent to her and an authority who checks voters' elegibility and can produce
blind signatures. Voters must be able to talk anonymously to the counter; this
requirement could be achieved with cryptographic tools that we will introduce
later such as mix-nets.

The FOO protocol assumes that there is some public-key infrastructure in place
in which each voter has a digital signature keypair and the association of
verification keys to voters is public. FOO requires each voter to perform four
steps:
\begin{enumerate}
\item Prepare a ballot on her own, sign it and save a private random value.
\item Authenticate herself to the authority and get a blind signature on the ballot.
\item Submit the ballot and authority signature anonymously to a ballot counter (this is equivalent to publishing the ballot).
\item After voting has closed, submit the private random value from step 1 to the counter, also anonymously.
\end{enumerate}

\begin{definition}
The FOO protocol is the following protocol for voters, an authority and a counter.
\end{definition}

\begin{description}
\item[Tools] The FOO protocol requires a digital signature scheme $\Sigma$, a
blind signature scheme $BS$ with an explicit form and a commitment scheme $CS$.
We write algorithms with the scheme name as prefix, for example $BS.\alg{Sign}$,
to avoid ambiguity.

\item[Voter] The voter starts out with a digital signature keypair $(sk_V,
vk_V)$ for $\Sigma$, a vote $v$ and the authority's blind signature
verification key $vk_A$.
\begin{enumerate}
\item She creates a commitment $(c, k) \gets CS.\alg{Commit}(v)$, blinds it as
$(b, u) \gets BS.\alg{Blind}(vk_A, c)$ and signs this as $\sigma_V \gets
\Sigma.\alg{Sign}(sk_V, b)$.
\item She then sends $(ID_V, b, \sigma_V)$ to the authority and expects a
blinded signature $s$ in return. Here $ID_V$ is some string describing the
voter's identity.
\item On receipt of $s$, she creates the blind signature $\sigma_A \gets \alg{Unblind}(vk_A, s, u)$ and sends her ballot $(c, \sigma_A)$ anonymously to the counter. The counter replies with some random identifier $i$.
\item After voting has closed and the counter has invited the voters to open
their ballots, the voter sends $(i, v, k)$ anonymously to the counter.
\end{enumerate}

\item[Authority]
The authority has a keypair $(sk_A, vk_A)$ for a blind signature scheme. She
also has access to a table $T$ of the identities and verification keys of all
eligible voters: $(ID_V, vk_V)$ for all voters $V$.
Further, the authority has a list $L$ of the identities, blinded ballots
and signatures of all voters who have already voted (this list starts out empty
of course).
When a voter sends the authority a triple $(ID_V, b, \sigma_V)$ the
authority checks that the voter is eligible to vote, i.e. $ID_V \in T$, and retrieves the corresponding verification key $vk_V$.
The authority then checks that the signature is valid: $\Sigma.\alg{Verify}(vk_V, b, \sigma_V) = 1$. If this is correct, the authority checks that the voter has not already voted, i.e. $ID_V$ does not appear in $L$.
The authority then adds $(ID_V, b, \sigma_V)$ to $L$ and returns a blind
signature $s \gets BS.\alg{Sign}(sk_A, b)$ to the voter.

At the end of the voting phase, the authority publishes the list $L$.

\item[Counter]
The counter starts out with the authority's verification key $vk_A$.
The counter holds no secrets and performs no secret operations: the entire
protocol for the counter can be performed in public and therefore checked by
anyone.

During the voting phase, the counter anonymously receives ballots $(c, \sigma)$.
She checks that each incoming ballot is valid, i.e. $BS.\alg{Verify}(vk_A, c,
\sigma) = 1$ and publishes all accepted ballots along with their signatures and
a unique identifier $i$, i.e. the counter maintains a list of entries $(i, c,
\sigma)$. The identifiers could be randomly chosen or simply sequence numbers.

At the end of the election, the counter invites all voters to open their
ballots. On receipt of an anonymous message $(i, v, k)$ the counter retrieves
the entry $(i, c, \sigma)$ and if such an entry exists, she computes $x \gets
CS.\alg{Open}(v, c, k)$. If this returns $1$, the ballot is valid and the
counter adds the vote $v$ to the set of valid votes. Finally, the counter
tallies all valid votes.
\end{description}

\subsubsection{Verifiability of FOO.}

We will briefly show why FOO is a verifiable protocol. Specifically, we check
the following properties.

\begin{description}
\item[Individual verifiability] Voters can check that their ballot was counted.
\item[Universal verifiability] Anyone can check that all ballots were counted
 correctly.
\item[Ballot verifiability] Anyone can check that all ballots correspond to
 correct votes.
\item[Eligibility verifiability] Anyone can check that only eligible voters have
voted, and only once each.
\end{description}

For individual verifiability, since the counter just publishes all ballots the
voter can check if her ballot is included among the published ones. Better
still, in case of a dispute the voter can expose a cheating counter if the
counter refuses to accept a correctly signed ballot.

Universal verifiability is easy since the counter holds no secrets: anyone can
repeat the count of all opened ballots. The same holds for ballot verifiability
since the ballots are opened individually.

For eligiblility, first note that anyone can verify that only correctly signed
ballots are counted. If we assume that the authority is honest then only
eligible voters will receive a signature from the authority and only once each.
Even if the authority is dishonest, its log $L$ would show if it had ever blind-
signed a ballot that was not accompanied by a correct signature from a
legitimate voter key, or if the authority had signed two ballots with a
signature from the same voter.

\subsubsection{Dispute resolution in FOO.}

In addition to verifiability, the FOO protocol provides a digital audit trail
that can be used to resolve many disputes which could arise. We mention some
cases that were addressed in the original paper; we imagine that all these
disputes could be brought before a judge or election official.
In the following we assume that honest parties' keys are not available to
cheaters. This means that in any dispute between a honest and a dishonest party,
the honest party will be able to convince a judge that the other side is
cheating - more precisely, that either the other side is cheating or her
signature has been forged.
In the following we give a list of possible accusations and how a judge should
respond.

\begin{itemize}
\item The authority refuses to give a legitimate voter a signature, or provides
her with an invalid signature.

The voter can publish a blinded ballot and her digital signature on it;
a judge can now ask the authority to either sign this ballot or give a reason
for refusing to do so. If the judge asks to see the authority's blinded
signature, the voter can reveal her vote and blinding factor to the judge who
can then check the unblinding step and verify the resulting signature.
This way, a cheating authority will always be exposed.

\item The authority claims that a voter has already voted.

A judge can ask for the voter's previous blinded ballot and digital signature as
proof. If the authority fails to produce this, she is exposed - if she does
produce this, the voter must explain why said blinded ballot carries a signature
under her key.

\item The authority signs a ballot that does not come from a legitimate voter,
or more than one ballot from the same voter.

The judge checks the counter's published ballots against the authority's list
$L$ for any signed ballots that do not have a valid voter-signature in $L$, or
two ballots with the same voter's signature.

\item The authority signs something that is not a legitimate ballot.

If the illegitimate ballot is never opened, it does not contribute to the result
and can be ignored. Once a ballot is opened, the judge can check its contents.
It is not the authority's fault if its signature is discovered on an invalid
ballot: since the authority's signature is blind, the authority has no way of
knowing the contents of what it signs.

\item A voter tries to vote more than once.

The judge checks that all the counter's ballots are also referenced in the list
$L$ and then checks the list $L$ for two different ballots with the same voter's
signature.

\item The counter refuses to accept a legitimate ballot.

The judge checks the signature on the disputed ballot; if it verifies and the
counter still refuses then the counter is exposed as a cheater. The same applies
to opening keys $k$ where the judge checks using the opening algorithm.

\item The counter accepts an illegitimate ballot without a valid signature).

The judge checks the signature; if it fails the counter is exposed as a cheater.
The same applies to opening information.

\item The counter produces a false result.

The judge recomputes the result and disqualifies the counter if the results do
not match.
\end{itemize}

\section{Homomorphic Voting}

The FOO protocol from the last section scores well on privacy, verifiability and
dispute resolution but has one major drawback: voters need to interact with the
voting system at two different times, once to cast their ballot and once again
after the voting period has ende to open their ballot. A different approach to
cryptographic voting voting removes this drawback.

\subsection{Motivation and example}

Here is another sketch of a ``physical'' voting protocol. Consider a yes/no
referendum. Each voter gets two balls of the same size and appearance except
that one weighs 1 lb\footnotemark and the other 2 lb. To vote no, the voter
writes her name on the lighter of two balls and places it on a tray; to vote yes
she does the same for the heavier one. This allows anyone to check that only
eligible voters have voted and only once each by comparing the names on the cast
ball(ot)s with a list of eligible voters. To tally the election, one first
counts the number of balls cast, then weighs the entire tray and derives the
number of light and heavy balls from the total amount and weight of the balls.
This way, the amount that each individual ball(ot) contributed to the tally is
hidden from everyone except the voter who cast it. One point that we will have
to take care of in the cryptographic protocol based on this idea is how we
prevent a voter from casting a forged ball weighing more than 2 lb to gain an
unfair advantage.

The cryptographic tool that we will use to build the equivalent of the balls
above goes by the name of ``homomorphic asymmetric encryption''. The adjective
homomorphic describes a scheme where individual elements (namely ciphertexts)
can be combined in such a way that the combined elements allow the same
operations as the individual ones, and the operations on the combined element
reflects the way you combined them. In the example above, you can weigh a tray
full of balls just like you can weigh an individual ball and the weight of the
full tray (minus the weight of the tray itself) is the sum of the weights of all
the individual balls.

Before we can define homomorphic asymmetric encryption, we first need to define
what asymmetric encryption is in the first place.

\footnotetext{One pound, abbreviated lb, is around 0.454 kg.}

\subsection{Asymmetric encryption}

Asymmetric or ``public key'' encryption is perhaps the best-known invention of
modern cryptography. It is certainly one of the oldest: it was first suggested
by Diffie and Hellman in 1976 \cite{DH76} and implemented successfully by
Rivest, Shamir and Adleman in 1978 \cite{RSA78}.

There are many ways to explain asymmetric encryption using physical terms: our
favourite example is a letter-box. Anyone can send you letters by placing them
in your letter-box but only you can get letters out of the box again\footnotemark. Indeed, once someone has placed a letter in your letter-box, even
they can't get it out again.

\footnotetext{The design of letter-boxes varies a lot between countries; we have
in mind the continental European style where letterboxes have a flap to insert letters and the owner can open a door on the letter-box with a key to retrieve letters.}

As for digital signatures, we
define the types of algorithms required and the security requirements.

\begin{definition}
An asymmetric encryption scheme $E$ is a triple of algorithms
\[ E = \left(
\alg{KeyGen}, \alg{Encrypt}, \alg{Decrypt}
\right) \]
where the key genration algorithm takes no input and returns a pair $(pk, sk)
\gets \alg{KeyGen}()$ known as the public and secret key. The encryption
algorithm takes a public key $pk$ and a message $m$ and returns a ciphertext $c
\gets \alg{Encrypt}(pk, m)$. The decryption algorithm takes a secret key $sk$
and a ciphertext $c$ and outputs either a decrypted message $d \gets
\alg{Decrypt}(sk, c)$ or declares the ciphertext invalid, which we indicate with
the special output symbol $\bot$. The decryption algorithm must be deterministic.

The correctness condition is that for any message $m$, the following operations
result in $d = m$:
\[
(pk, sk) \gets \alg{KeyGen}();\ 
c \gets \alg{Encrypt}(pk, m);\ 
d \gets \alg{Decrypt}(sk, c)
\]
\end{definition}

\subsubsection{Security of encryption.}
It took the community of cryptographers some time to come up with the definitions
of security for asymmetric encryption that are in use today. The first obvious condition --- given a ciphertext you should not be able to tell the contained message --- is unfortunately insufficient. Here is an example why.
Alice, a famous cryptographer, wishes to announce the birth of her child to her family while keeping its gender secret from the world at large for now. Eve, an eavesdropper from the press, obtains Alice's ciphertext. Eve may be able to guess that the message is either ``It's a boy!'' or ``It's a girl!''. It is not enough for Alice if Eve is unable to decrypt ciphertexts of completely unknown messages, Eve should not even be able to tell which of two particular messages (both of which Eve can guess) Alice chose to encrypt.

Further, suppose this is Alice's second child and her last child was a girl. If Eve can compare Alice's ciphertext with the ciphertext she sent to her family to announce the birth of her last child and the two ciphertexts turn out to be identical, Eve might be able to conclude that Alice encrypted the same message both times without ever decrypting anything. If Alice is using an asymmetric scheme, Eve can even encrypt any messages she likes herself under Alice's family's public keys and compare the ciphertexts to the one sent by Alice. So another condition on asymmetric encryption must be that if you encrypt the same message twice, you get different ciphertexts each time and if you are given two ciphertexts, you cannot tell whether they encrypt the same message or not.

The first security requirement for encryption is known as indistinguishability
under chosen plaintext attack, abbreviated IND-CPA. Here, the attacker mey chose
any two messages, send them to the security game and get an encryption of one of
them back; a scheme is called IND-CPA secure if she cannot tell which message
the security game chose to encrypt.

\begin{definition}
An asymmetric encryption scheme $E$ is IND-CPA secure if no attacker can win the
following game with better probability than $1/2$, the probability of guessing
at random.

\begin{description}
\item[Setup] The game creates a keypair $(pk, sk) \gets \alg{KeyGen}()$ and
gives the attacker the public key $pk$. The game also picks a bit $b$ randomly
from $\{0, 1\}$ and keeps this secret.
\item[Moves] Once in the game, the attacker may pick a pair of messages $m_0$
and $m_1$ of the same length$^\dagger$ and send them to the game. The game
encrypts $c \gets \alg{Encrypt} (pk, m_b)$ and returns this to the attacker.
\item[Winning conditions.] The attacker may make a guess at $b$ which ends the
game. The attacker wins if she guesses correctly.
\end{description}
\end{definition}

\noindent($^\dagger$) The condition that the two messages be of the same length
is to avoid the attacker guessing the message from the ciphertext length. In the
example above, ``boy'' has three letters but ``girl'' has four so any encryption
scheme that returns a ciphertext with the same number of characters as the
message is vulnerable to such an attack and Alice should pad both her messages
to the same length to be safe. In practice, many encryption schemes work not on
characters but on blocks of characters in which case the restriction can be
weakened to both messages producing the same number of ciphertext blocks; the
ElGamal scheme which we will consider later operates on messages in a fixed
group where all messages have the same length ``1 group element'' and this
condition is vacuous.

\textcolor{Fuchsia}{Introduce NM and CCA here? Put instantiation (ElGamal) here or in separate section?}

\subsection{Homomorphic encryption.}
A homomorphic encryption scheme offers an additional algorithm \alg{Add} that takes two ciphertexts and a public key and produces a new ciphertext for the ``sum'' of the two messages in the original ciphertexts. We put ``sum'' in quotes because the principle can be applied to different operations such as multiplication as well.

\begin{definition}
An asymmetric encryption scheme $E$ is homomorphic if there are these additional operations:

\begin{itemize}
\item An operation $+$ on the message space.
\item An algorithm \alg{Add} that takes a public key $pk$ and two ciphertexts $c_1, c_2$ and outputs another ciphertext $s$.
\end{itemize}

The correctness condition is that for any messages $m_1, m_2$ the following returns $d = m_1 + m_2$:
\[
\begin{array}{l}
(pk, sk) \gets \alg{KeyGen}();\ 
c_1 \gets \alg{Encrypt}(pk, m_1);\ 
c_2 \gets \alg{Encrypt}(pk, m_2);\ \\
c \gets \alg{Add}(pk, c_1, c_2);\ 
d \gets \alg{Decrypt}(sk, c)
\end{array}
\]

Further, if $c_1, c_2$ are ciphertexts for $m_1, m_2$ as above and $c$ is obtained as $c \gets \alg{Add}(pk, c_1, c_2)$ then not only is $c$ a ciphertext for $m_1 + m_2$ but for some choice of random values, $\alg{Encrypt}(pk, m_1 + m_2)$ could directly produce $c$.
\end{definition}

The last condition says that summed ciphertexts have the same form as ones encrypted directly. This prevents the following degenerate construction: a ``ciphertext'' is a list of ciphertexts, the encryption algorithm returns a list with one element and \alg{Add} just returns a list containing its two input ciphertexts. The decryption algorithm takes a list, decrypts each element individually and returns the sum of all decryptions.

\textcolor{Fuchsia}{What we actually want is that a sum-ciphertext hides how it was made. The fully formal definition over finite groups does this via the argument that if you perform a group operation with a uniform group element, the result is uniform (and this holds w.r.t. both message and randomizer groups). Do we want to (i) ignore this, perhaps saying that our definition is slightly simplified (ii) develop the whole machinery of groups and randomness to do it properly or (iii) do something else?}

\subsubsection{Prime-order groups.}
We are now working towards the ElGamal encryption scheme that we will use to
build a toy voting scheme called ``minivoting'' and then extend this to get the
Helios voting scheme. ElGamal uses a prime-order group, we sketch a
number-theoretic construction. To set up such a group, one typically picks a
prime $p$ such that $q = (p-1)/2$ is also prime (this is even more essential
than for RSA, to avoid ``small subgroup'' problems). The group $\mathbb Z^*_p$
with multiplication modulo $p$ has $p - 1$ elements; since $p$ is a large prime
and therefore is odd there will be a factor $2$ in $p-1$. If $(p-1)$ factors as
$2 \cdot q$ where $q$ is also prime and we pick an element $g \in \mathbb Z^*_p$
of order $q$ then the subgroup $G := \langle g \rangle \subset \mathbb Z^*_p$ is
itself a cyclic group of order $q$. Since $q$ is prime, $G$ has no true
subgroups, i.e. apart from the identity, there is no extra ``structure'' to be
discovered by examining the traces of individual group elements\footnotemark.
\footnotetext{More formally, for any two distinct elements $x, y$ that are not
the identity there is a unique isomorphism that takes $x$ to $y$, namely $(a
\mapsto y\cdot x^{-1}\cdot a)$.}

The ElGamal encryption scheme lives in such a group $G$ given by parameters $(p,
q, g)$. Since $G$ is isomorphic to $\mathbb Z_q$, we have an inclusion $\mathbb
Z_q \to G, (x \mapsto g^x \pmod{p})$. This map is efficient to compute
(square-and-multiply and variations) but is considered to be hard to invert. Its
inverse is known as taking the discrete logarithm of a group element. Further,
given two group elements $h$ and $k$, there are unique integers $a, b \in
\mathbb Z_q$ such that $h = g^a \pmod{p}$ and $k = g^b \pmod{p}$. The group
operation sends such $(h, k)$ to $h \cdot k = g^{a + b} \pmod{p}$. We can define
a further operation $\otimes$ that sends such $(h, k)$ to $g^{a \cdot b}
\pmod{p}$. This turns out to be a bilinear map on $G$ called the Diffie-Hellman
product and it is considered to be hard to compute in general; computing it for
random $h, k$ is the computational Diffie-Hellman problem. For random $h, k$ and
another group element $z$, it is even considered hard to tell whether $z = h
\otimes k$ or $z$ is just another random group element, this is called the
computational Diffie-Hellman problem. However, if you are given the integer $a$
(from which you could easily compute $h = g^a$ in $G$) then you can easily take
the Diffie-Hellman product with any $k$ as $h \otimes k = k^a \pmod{p}$.

From this we can define Diffie-Hellman key generation, as used in the ElGamal
encryption scheme:

\begin{definition}
A Diffie-Hellman group is a group $\langle g \rangle \subset \mathbb Z^*_p$ of
order $q$ for $p, q$ primes with $(p-1)/2 = q$. Such a group is given by
parameters $(p, q, g)$ and such parameters can be public and shared among all
users of a cryptosystem.

To generate a Diffie-Hellman keypair, pick parameters if required and pick an
$x$ at random from $\mathbb Z_q$, then set $y = g^x \pmod{p}$. Your secret key
is $x$ and your public key is $y$.
\end{definition}

Two comments on this scheme are in order. First, the group has order $q$ but is
represented as a subgroup of $\mathbb Z^*_p$. This can lead to some confusion
in implementations --- Cortier and Smyth \cite{CS???} identified a bug in an
early version of the Helios voting system which mixed up the two. The rule to
remember is, always reduce group elements modulo $p$ and integers (exponents)
modulo $q$. This is why you pick your secret key from $\mathbb Z_q$ (it's in
integer) and then compute the public key modulo $p$ (a group element).

Secondly, there are other possible realisations of cryptographically useful
prime-order groups in which the Diffie-Hellman product and discrete logarithms
are assumed to be hard. The most popular alternative uses a representation on an
elliptic curve over a finite field; we will not go into details of the
construction in this work but the ElGamal encryption scheme works identically
whether you are useing a $\mathbb Z^*_p$ group or an elliptic curve group.

\subsubsection{ElGamal.}
The ElGamal encryption scheme \cite{E85} was invented in 1985.
It encrypts a message $m \in G$ as a pair $(c, d)$.
First, the message is multiplied with a random group element, resulting in a
uniformly distributed group element (one-time pad); this is the role of $d$.
To allow the key-holder, and her only, to decrypt, an additional element $c$ is provided. The encryption procedure is:
\begin{enumerate}
\item Pick a random integer $r$ in $\mathbb Z_q$.
\item Set $d = m \cdot y^r \pmod{p}$ where $y$ is the public key. Since $r$ was
uniformly random in $\mathbb Z_q$, $d$ is uniformly random in $G$.
\item Set $c = g^r \pmod{p}$. This is the decryption information.
The ciphertext is the pair $(c, d)$.
\end{enumerate}
Since $m = d/(c \otimes y)$, the decryptor can compute $m$ with her secret key;
for anyone else extracting the message is equivalent to solving the
computational Diffie-Hellman problem and telling which of two messages was
encrypted (the IND-CPA security game) is equivalent\footnotemark\ to solving the
decisional Diffie-Hellman problem.
\footnotetext{To be exact, there is a loss of a factor $1/2$ due to a conversion
from a left-right game to a real-or-random one.}

We summarise the algorithms again:
\begin{definition}
The ElGamal encryption scheme is the encryption scheme given by the algorithms below.
\end{definition}
\begin{description}

\item[\alg{KeyGen}] Pick or obtain parameters $(p, q, g)$. Pick $sk$ at random
from $\mathbb Z_q$ and set $pk = g^{sk} \pmod{p}$, return $(pk, sk)$.

\item[\alg{Encrypt}$(pk, m)$] Pick $r$ at random from $\mathbb Z_q$ and set
$c = g^r \pmod{p}, d = m \cdot pk^r \pmod{p}$. Return $(c, d)$.

\item[\alg{Decrypt}$(sk, (c, d))$] Compute $m = d / c^{sk} \pmod{p}$.
\end{description}

ElGamal is homomorphic but the operation is not as useful as we would like:
for ciphertexts $(c, d)$ and $(c', d')$ we can set
\[
\alg{Add}((c, d), (c', d')) := (c \cdot c' \pmod{p}, d \cdot d' \pmod{p})
\]
such that for messages $m, m'$ in $G$ we get a ciphertext for $m \cdot m'
\pmod{p}$. What we would really like for voting is a scheme where messages lie
in the additive group $\mathbb Z_q$ and we can perform homomprphic addition,
rather than multiplication, of ciphertexts. If our messages are restricted to
small integers (indeed, in our ballots they will be wither $0$ or $1$) then we
can use a variation called exponential ElGamal: to encrypt an integer $m$,
replace the $d$-component with $g^m \cdot pk^r \pmod{p}$. For two ciphertexts
$(c, d)$ for $m$ and $(c', d')$ for $m'$ the \alg{Add} operation now produces a
ciphertext that decrypts to $g^{m + m' \pmod{q}}$ as desired. While getting the
exponent back from an arbitrary group element is hard (the discrete logarithm
problem), for small enough exponents this can be done just by trying $g^0, g^1,
g^2, \ldots$ until we find the correct decryption. This is the approach taken by
Helios, which we will replicate in our minivoting scheme as a first step towards
constructing Helios.

\subsection{Minivoting}

We can now build a first voting scheme out of a homomorphic encryption scheme.
This first scheme was called ``minivoting'' by its authors Bernhard, Cortier,
Pereira, Smyth and Warinschi and presented at Esorics 2011 \cite{BCPSW11}.
Minivoting is not verifiable and indeed is only secure against passive attackers
who cannot send malformed ciphertexts. By adding further components to
minivoting, it can be turned into something very much like the real Helios
scheme.

\textcolor{Fuchsia}{TODO --- mention authentic channels, could be achieved with signatures etc.}

\begin{definition}
Minivoting is the following voting scheme for a yes/no question, based on a
homomorphic asymmetric encryption scheme $E$ with a message space $\mathbb Z_n$
for some $n$ larger than the number of voters.
\begin{description}
\item[Participants] Minivoting requires one authority, a public bulletin board
to which everyone can post authenticated messages and any number of voters
smaller than $n$.
\item[Setup]
The authority creates a key pair $(pk, sk) \gets E.\alg{KeyGen}$ and posts $pk$
to the bulletin board.
\item[Voting] Voters read the public key $pk$ off the board. They choose $v = 1$
for ``yes'' and $v = 0$ for ``no'' and create a ballot $b \gets
E.\alg{Encrypt}(pk, v)$ which they post on the board.
\item[Tallying] The authority uses the $E.\alg{Add}$ operation to add all
ballots, creating a final ballot $s$ which she decrypts as $d \gets E.\alg{Decrypt}
(sk, s)$. The authority then counts the number $m$ of ballots submitted and
posts the result ``$d$ yes, $m-d$ no'' to the board.
\end{description}
\end{definition}

\section{Privacy}

Following the principles set out by the IND-CPA game for encryption, we give a
notion of ballot privacy against observers for voting schemes. The attacker can
choose two votes for each voter and the voters will either cast the first or
second vote (all voters make the same choice which of the two to cast). The
attacker's aim is to tell which choice the voters made, just like the IND-CPA
game asks the attacker to tell which of two messages was encrypted. Since the
two results that this game produces may differ, which would immediately tell the
attacker what is going on, the game will always report the first result.

\begin{definition}
A voting scheme has ballot privacy against passive attackers (observers) if no
attacker can do better in the following game than guess at random (with
probability $1/2$).

\begin{description}
\item[Setup] The game picks a bit $b$ at random and keeps it secret. The game
then sets up the voting scheme and plays the voters, authorities and bulletin
board.

\item[Moves] Once for each voter, the attacker may choose two votes $v_0$ and
$v_1$. The game writes down both votes. If $b = 0$, the game lets the voter vote
for $v_0$; if $b = 1$ the game lets the voter vote for $v_1$.

The attacker may ask to look at the bulletin board at any point in the game.

When all voters have voted, the game gives the attacker the result computed as
if everyone had cast their first ($v_0$) vote.

\item[Winning conditions]
At any point in the game, the attacker may submit a guess for $b$. This ends the
game immediately. The attacker wins if her guess is correct.
\end{description}
\end{definition}

Although we do not prove it here, we could show that if there is an attacker
with a better than random chance of winning this game for the minivoting scheme
(based on any homomorphic encryption scheme) then we can use the attacker to
make a better than random guess at the IND-CPA game for the same encryption
scheme. The rough idea is that any attacker guessing better than at random for
the ballot privacy game must have selected at least one voter and given her
different votes $v_0$ and $v_1$, so we could run the IND-CPA game with messages
$v_0$ and $v_1$ and use the attacker's guess to make our guess at which one was
encrypted. The challenge is that the IND-CPA game allows exactly one challenge
move whereas the ballot privacy game allows many voters. This gives us the
following proposition.

\begin{proposition}
For any IND-CPA secure homomorphic asymmetric encryption scheme, the derived
minivoting scheme has ballot privacy against observers.
\end{proposition}

In particular this holds for the minivoting scheme based on ElGamal.

\begin{structure}
\begin{itemize}
\item bad ballots (solution: PoKs)
\item Cortier-Smyth attacks (solution: non-malleable ballots)
\item Trustee can decrypt individual ballots (solution: threshold)
\end{itemize}
\end{structure}

\subsection{Problems}

Minivoting is not a secure scheme if some of the participants may misbehave.
\begin{enumerate}
\item A voter may encrypt $g^2$ to get an unfair advantage.
\item For more complex ballots than yes/no questions, voters have even more ways
to cheat.
\item A voter can stall the election by submitting a ballot for $g^r$ for some
random $r$ --- no-one will be able to decrypt the result anymore.
\item You have to trust the authority that they have announced the correct
result.
\end{enumerate}

Luckily, cryptographers have found solutions to all these problems. They are:
\begin{enumerate}
\item Zero-knowledge proofs.
\item Zero-knowledge proofs.
\item Zero-knowledge proofs.
\item Zero-knowledge proofs.
\end{enumerate}

Zero-knowledge proofs are a technique to turn any protocol secure against
observers into a protocol secure against misbehaving participants. The idea is
that whenever a participant submits some information (say, a ballot) they must
submit two things: first, the ballot and secondly, a proof that they have made a
correct ballot. The zero-knowledge part is that these proofs reveal nothing
beyond that the ballot is correct. In particular, a proof that your ballot is
correct does not leak your vote.

Before we can discuss the proofs that Helios voters will make in their ballots,
we must first give the general ballot format for more complicated questions.

\subsubsection{The ballot format.}
Homomorphic ballots are possible not just for yes/no questions but for a number
of voting/election setups including first-past-the-post, approval voting and
top-$k$-of-$n$ elections. All these formats have in common that a voter answers
a question by ticking some (or all, or none) of a predefined set of checkboxes
and the election result is essentially a list, for each box, of how many voters
ticked this box.
Homomorphic voting in the above sense cannot handle write-in votes or ranked
(Borda, Condorcet, Instant runoff etc.) counts.

For example, in a first-past-the-post election for three candidates A, B and C,
voters will be presented with three boxes --- obviously labelled A, B and C ---
and must tick exactly one box each (or possibly none, to cast a blank vote). The
election result is the number of votes that A, B and C each got, from which one
can form the sum and determine the turnout and the percentage of votes that each
candidate got.

A ballot will contain one ciphertext for each option (checkbox). These
ciphertexts will be encryptions of either 0 or 1. In addition, once we have
introduced zero-knowledge proofs, each ciphertext will be accompanied by a proof
that it really contains 0 or 1; these proofs are known as individual proofs. If
the election specification sets limits on the numbers of boxes you can/must
check, there will be one further proof attesting to this known as the overall
proof. Of course a ballot can be composed of several structures as jsut
described, allowing for multiple questions in a poll or multiple races in an
election.

\subsubsection{Attacks against the ballot format and ballot weeding.}
Cortier and Smyth \cite{CS???} pointed out the following problem with bulletin
board based elections. Suppose there are three voters, Alice, Bob and Eve. Alice
and Bob both cast ballots. Next, Eve reads Alice's ballot off the board and
submits a copy of it as her own ballot. The election result is now announced as
2 yes, 1 no: Eve knows that Alice must have voted yes and Bob no, since the two
copied ballots must enrypt the same vote. However, in a truly private election,
Eve should never be able to tell whether Alice votes yes and Bob no or the other
way round, since these two scenarios both make the same contribution to the
result. If the result is that everybody voted yes then Eve can deduce that Alice
voted yes too, which is unaviodable --- the problem with ballot copying is that
Eve can find out more than she could by just observing the result.

A first reaction to this problem could be to introduce ballot weeding in the
following sense: we reject any ballot that is an exact copy of a ballot already
on the board. If ballots are non-malleable ciphertexts, this is actually
sufficient --- however, homomorphic ciphertexts can never be non-malleable as
Eve can always \alg{Add} an encryption of $g^0$ to an existing ciphertext. Eve
will still know that the two ciphertexts encrypt the same vote but no-one else,
even the decryptor, can tell such a ``rerandomised'' ciphertext from a genuine
ballot by a voter who just happened to vote for the same choice as Alice.

We can solve this problem and the problem of Eve voting for $g^2$ in one go by
adding a non-malleable zero-knowledge proof to each ciphertext. Ballot weeding
will now reject any ballot that shares a proof with a previous ballot. In fact
we even fix one more problem that Cortier and Smyth identified with the original
ballot format. Consider a poll for choices A, B and C so ballots take the form
\[
(c_A, \pi_A, c_B, \pi_B, c_C, \pi_C, \pi_O)
\]
where $c_A$ is the ciphertext for choice $A$, $\pi_A$ is the individual proof
that $c_A$ is well-formed and $\pi_O$ is the overall proof (that at most one
of $c_A, c_B, c_C$ encrypts a 1). If the above is Alice's ballot, Eve can submit
the following modified ballot:
\[
(c_B, \pi_B, c_A, \pi_A, c_C, \pi_C, \pi_O)
\]
The result is that Eve has swapped the A- and B-components of Alice's ballot around but she knows exactly what the relations between the original and
modified ballot are and can use this knowledge to attack Alice's privacy. In
Helios version 3, after you submitted a ballot, the hash of your ballot was
sent to you as a confirmation value and the hashes of all ballots were displayed
on a ``short board'', with the ``full board'' of all ballots also available. The
point here is that Eve's ballot will have a completely different hash value to
Alice's and while Helios prevented Eve from submitting a ballot with the same
hash value as Alice's (i.e. making an exact copy), this modified ballot was
accepted by Helios without complaint. It could be detected by auditing the full
board but code for this was not available in Helios at the time.

\textcolor{Fuchsia}{TODO --- introduce the actual proofs; some $\Sigma$-theory}

\subsection{Threshold encryption}



\section{Verifiability}

\section{Putting it all together}

% optional?
\section{Mix-nets}

\begin{thebibliography}{XXX11}
\bibitem[FOO92]{FOO92}
A. Fujioka, T. Okamoto and K. Ohta.
A Practical Secret Voting Scheme for Large Scale Elections.
In: ???

\bibitem[US11]{US11}
D. Schr\"oder and D. Unruh.
Security of Blind Signatures Revisited.
eprint, report 2011/316.

\end{thebibliography}

\end{document}

