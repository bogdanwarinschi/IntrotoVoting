\documentclass{llncs}
%DB: presume this is the correct class

\usepackage[dvipsnames]{xcolor}
\newenvironment{structure}{
  \begin{color}{ForestGreen}
}{
  \end{color}
}

\newcommand{\alg}[1]{\textup{\texttt{#1}}}

\begin{document}

\section{Introduction}

\begin{structure}
Outline target audience, presentation strategy (incremental requirements based on attacks), gap we fill, our emphasis on rigourous models
\end{structure}

This chapter aims to present voting from a cryptographer's point of view. We
will state some security properties that one could desire of a voting scheme and
present methods to achieve these properties using cryptography. 

\section{First steps}

\begin{structure}
motivating example, realisation (envelopes), security/trust models;
primitives required for crypto implementation, FOO
\end{structure}

\subsection{Example}

Here is one way to run a poll. Voters enter a polling station and pick up a voting card on which the candidates standing for election or choices in a referendum are printed. They fill in their card by placing crosses in boxes. Then they take their card and put it in an opaque envelope which they seal. In keeping with the cryptographic constructions we will describe later, we call such an envelope containing a filled in vote card a ``ballot''. This completes the first step, ballot creation.

To cast their ballots, voters present them to an official along with some identification. The official checks that the voter is registered at this polling station and has not cast a vote yet, but the official does not get to see the vote itself. Then the official places the ballot-envelope in a stamping machine and stamps the envelope, in such a way that the imprint of the stamp is not only visible on the envelope but also transferred to the vote card within.

Voters post their ballots to a counting centre. The postal service agrees to send any correctly stamped envelope free of charge from anywhere in the country so voters can post their envelope anonymously in any post box that they choose. 
The counting centre shuffles all received envelopes again, opens them and counts all vote cards that contain an imprint of the official stamp.

\subsection{Thinking about security}

\subsection{Cryptographic primitives}

\begin{structure}
\begin{itemize}
\item digital signatures
\item blind signatures
\item commitments
\end{itemize}
\end{structure}

\subsubsection{Digital signatures.}

% DB: This is a new section (nothing to copy across like for encryption/PoKs) so
% I'll try making a first attempt at writing something for it now.

Digital signatures are the cryptographer's replacement for signatures or stamps.
If we know what someone's signature looks like and believe that it would be hard
for anyone but the owner to produce such a signature, the presence of such a
signature on a document attests that the owner has seen and signed it.
Similarly, the imprint of a stamp on a document attests that someone with the
appropriate stamp has seen the document.

Digital signatures differ from phyiscal ones in that they are not placed on an
original document, modifying the original, but are separate objects that can be
provided alongside the original. As a consequence, to prevent someone from
transferring a signature from one document to another, digital signatures for
different documents will be completely different objects.

To be able to create digital signatures, a signer first has to generate a pair
of keys called the signing key (or secret key) and verification key (or public
key). To do this, a digital signature scheme defines a key generation algorithm.
The signing key is like a stamp with which the signer can stamp documents. Such
a stamp on a document does not mean much on its own (anyone can create their own
stamps) but if you know what a particular person's or organisation's stamp looks
like, you can verify any stamped document to see if it was really stamped by the
person or organisation you know, by comparing the imprint on the document with
the imprint you know to be theirs. The verification key plays a similar role for
digital signatures.

A digital signature scheme comes with two more algorithms. The signing algorithm
takes a document and a signing key as input and returns a signature for the
document. The verification algorithm takes a document, a signature and a
verification key and outputs 1 if the signature is valid for the given key and
document, otherwise 0.

It is the signer's responsibility that all verifiers have an authentic copy of
the verification key. For example, in some government e-ID card schemes every
citizen gets a smartcard containing a signing key and the government maintains a
public database of verification keys. For a digital election, if the election
authorities need to sign ballots they can publish their verification key as part
of the election specification.

\begin{definition}
A digital signature scheme $\Sigma$ is a triple of algorithms
\[
\Sigma = \left( \alg{KeyGen}, \alg{Sign}, \alg{Verify} \right)
\]
known as the key generation, signing and verification algorithms and satisfying
the correctness condition below.

The key generation algorithm takes no input and produces a pair of keys $(sk,
vk) \gets \alg{KeyGen}()$ known as the signing and verification keys. The siging
algorithm takes a signing key $sk$ and a message $m$ as inputs and produces a
signature $\sigma \gets \alg{Sign}(sk, m)$. The verification algorithm must be
deterministic. It takes a verification key $vk$, a message $m$ and a signature
$\sigma$ as inputs and returns $0$ or $1$. We say that $\sigma$ is a (valid)
signature for $m$ under key $vk$ if $\alg{Verify}(vk, m, \sigma) = 1$.

A digital signature scheme must satisfy the following correctness condition
which means that correctly generated signatures are always valid. For any
message $m$, if you run the following sequence of algorithms then you get $b =
1$:
\[
(sk, vk) \gets \alg{KeyGen}();\ \sigma \gets \alg{Sign}(sk, m);\ b \gets \alg{Verify}(vk, m, \sigma)
\]
\end{definition}

This definition tells you what a digital signature scheme is and how to use it
but does not yet say anything about security. It is common in cryptography to
define a class of schemes in two parts, keeping functionality and security
separate. This has many advantages including that we can reason about several
different levels of security for the same class of schemes.

\subsubsection{Security models.}
We introduce the cryptographer's viewpoint of security using digital signatures
as an example. Security means that an attacker can not do certaing things, like
create a signature on a document that verifies under someone else's key. To
formalise this, it is common to define a cryptographic game which captures
exactly what we want an attacker not to be able to do. The security definition
is then the claim that no attacker can win the given game.

Security games can be defined in three parts. First, the game begins with some
setup algorithm. Secondly, we give one or more moves that the attacker can play
in the game. Finally, we state the winning conditions for the attacker.

\subsubsection{Security of digital signatures.}
An obvious property that signatures should have is that you cannot forges a
signature on a message that verifies under someone else's key. We call such a
forgery an existential forgery and we call an attacker that produces such a
forgery a no-message attacker (we will see why in a moment). The security game
and notion for this property have the game create a key pair and give the
adversary the verification key, which is supposed to be public. The adversary
wins if she produces a forgery:

\begin{definition}
A digital signature scheme is existentially unforgeable under no-message attacks
(EF-NMA) if no attacker can win the following game.

    \begin{description}
    \item[Setup] The game creates a key pair $(sk, vk) \gets \alg{KeyGen}()$ and
                 saves them; the attacker gets the verification key $vk$.

    \item[Moves] None in this game.

    \item[Winning conditions] The attacker wins the game if she provides a
    message/ signature pair $(m^*, sk^*)$ such that this pair verifies under the
    game's key: $\alg{Verify}(vk, m^*, \sigma^*) = 1$.
    \end{description}
\end{definition}

This definition is considered necessary but not sufficient. The attacker may be
a participant in some system using digital signatures in which she gets to see
messages legitimately signed by some other person; she should still not be able
to forge anyone else's signature on any message they did not sign. This includes
such attacks as taking a signature off one message and claiming that the signer
actually signed some other message. Cryptographers model this with the chosen-
message attack game. Here the adversary gets an extra move: she may ask the game
to sign any messages of her choice and wins if she can forge a signature on any
message that the game did not sign.

\begin{definition}
A digital signature scheme is existentially unforgeable under chosen message
attacks (EF-CMA) if no attacker can win the following game.

\begin{description}
\item[Setup] The game creates a key pair $(sk, vk) \gets \alg{KeyGen}()$ and
saves them; the attacker gets the verification key $vk$. The game also makes an
empty list $L$ of signed messages.

\item[Moves] The attacker may, any number of times, send the game a message $m$
of her choice. The game signs this message producing a signature $\sigma \gets
\alg{Sign}(sk, m)$, adds $m$ to $L$ and returns $\sigma$ to the attacker.

\item[Winning conditions] The attacker wins the game if she provides a message/
signature pair $(m^*, sk^*)$ such that (1) this pair verifies under the game's
key: $\alg{Verify}(vk, m^*, \sigma^*) = 1$ and (2) the game never signed the
message $m^*$, i.e. $m^* \notin L$.
\end{description}
\end{definition}

In neither of the above games would it make any difference if we gave the
attacker an extra move to verify signatures: she already knows the verification
key $vk$ so she can do this herself.

\textcolor{blue}{DB: do UF-CMA too?}

\subsubsection{Blind signatures.}
Voting is one of several applications where it is useful to be able to sign
messages without knowing their content. To ensure that only authorized voters
cast ballots, one could ask voters to authenticate themselves with an authority
who holds a signing key and signs the ballots of authorized voters.
Unfortunately, a straightforward use of digital signatures here would reveal
everyone's votes to the authority. Instead, one can use blind signatures: each
voter fills in her ballot and blinds it, then authenticates herself to the
authority that signs the blinded ballot without knowing its contents. The voter
then turns the signature on the blinded ballot into a signature on the real
ballot and casts this ballot along with the signature.

Blind signatures will require two security properties. Security for the signer
requires that no-one can forge signatures on messages that the signer has not
blind-signed, even though the signer will not usually know which messages she
has signed. Security for the user (in our case, the voter) requires that the
signer cannot learn which messages she has signed. We follow Schr\"oder and
Unruh \cite{US11} in the definition of security properties.

\begin{definition}
A blind signature scheme $BS$ is a tuple of algorithms
\[
BS = \left(
\alg{KeyGen}, \alg{User}, \alg{Signer}, \alg{Verify}
\right)
\]
The key generation algorithm takes no input and returns a pair of keys $(sk, vk)
\gets \alg{KeyGen}$ called the signing and verification keys. \alg{User} and
\alg{Signer} are a pair of interactive algorithms. The user algorithm takes a
message $m$ as input, the signer algorithm takes a signing key $sk$ as input.
When these two algorithms interact, the user gets a signature $\sigma \gets
[\alg{User}(m), \alg{Signer}(sk)]$ and the signer gets no output.
The verification algorithm is determinstic and takes a verification key, message
and signature as input and outputs 0 or 1. We call a signature $\sigma$ valid
for message $m$ and key $vk$ if $\alg{Verify}(vk, m, \sigma) = 1$.

A blind signature scheme $BS$ must have the following correctness property: for
any message $m$, running
\[
(sk, vk) \gets \alg{KeyGen}();\ \sigma \gets [\alg{User}(m), \alg{Signer}(sk)];\ 
b \gets \alg{Verify}(vk, m, \sigma)
\]
returns $b = 1$.
\end{definition}

\begin{definition}
A blind signature scheme is unforgeable (secure for the signer) if no attacker
can win the following game.

\begin{description}
\item[Setup] The game creates a key pair $(sk, vk) \gets \alg{KeyGen}$ and saves
them. It also creates a list $L$ of signed messages which starts out empty. The
attacker gets $vk$.

\item[Moves] The attacker may submit a message $m$ for signing as long as
$m \notin L$. The game runs $\sigma \gets [\alg{User}(m), \alg{Signer}(sk)]$,
adds $m$ to $L$ and returns the signature $\sigma$. The attacker may use this
move as many times as she likes.

\item[Winning conditions] The attacker wins if she can output a list of message/
signature pairs
\[
((m_1, \sigma_1), (m_2, \sigma_2), \ldots, (m_{k+1}, \sigma_{k+1}))
\]
satisfying the following conditions: (1) all messages are distinct: $m_i \neq m_j$
for all pairs $(i, j)$ with $i \neq j$ (2) all pairs verify i.e.
$\alg{Verify}(vk, m_i, \sigma_i) = 1$ for all $i$ and
(3) the attacker has made at most $k$ signature moves, i.e. fewer than the number
of messages she returns.
\end{description}
\end{definition}

The list $L$ here serves a slightly different purpose than for plain digital
signatures: it prevents the attacker from submitting the same message twice. The
winning condition is that the attacker has produced signatures on more messages
than she has used in signing moves, so at least one of her output pairs is a
genuine forgery. The reason for this formulation is that some blind signature
schemes allow you to take a message signature pair $(m, \sigma)$ and create a
new signature $\sigma' \neq \sigma$ on the same message such that $(m, \sigma')$
is still a valid message/signature pair on the same key.

The definition of blindness is a so-called indistinguishability game. Here, an
attacker's success cannot be measured in a single experiment but only as the
probability that an attacker is successful on average. The game will start by
picking a bit $b$ and will act differently depending on the bit. The attacker's
aim is to guess the bit $b$ and the security definition says that the attacker
cannot do better than guess at random.

In the blindness game, the attacker takes the role of the signer. She may
interact with two users bringing messages of the attacker's choice to be signed;
her aim is to guess which order the users come in.

\begin{definition}
A blind signature scheme is blind (secure for the user) if no attacker can guess
the bit $b$ in the following game with better probability than one half.

\begin{description}
\item[Setup]
The game picks a bit $b$ at random from the set $\{0, 1\}$.

\item[Moves]
The attacker has only one move and she may use it only once. First, the attacker
may send the game a verification key $vk$. The attacker may then choose a pair
of messages $(m_0, m_1)$ and send them to the game. The game starts two user
processes, the first one for $m_b$ and the second one for $m_{1-b}$, both of
which interact with the attacker (who takes the role of signer, but may do
anything she likes). If this results in both users getting a valid signature,
the attacker gets the signatures $(\sigma_0, \sigma_1)$ on $m_0$ and $m_1$
respectively.

\item[Winning conditions]
The adversary may make a guess for $b$ at any time. This stops the game.
The adversary wins if the guess is correct.
\end{description}
\end{definition}

\subsubsection{Explicit form of blind signatures.}
The above definition of blind signatures applies to many different schemes.
Some of these schemes have a more explicit form however that is easier to work
with in cryptographic proofs. We follow the presentation of Fujoka et al. \cite{FOO92} since we are working towards their voting protocol; a blind signature scheme that has an explicit form is for example the one of Chaum \cite{C85}.

\begin{definition}
A blind signature scheme in explicit form is a tuple
\[
BS = \left( \alg{KeyGen}, \alg{Blind}, \alg{Sign}, \alg{Unblind}, \alg{Verify} \right)
\]
of algorithms where \alg{Verify} is deterministic and the rest may be
randomized. The key generation algorithm outputs a keypair $(sk, vk) \gets
\alg{KeyGen}()$. The blinding algorithm takes a message $m$ and a verification
key $vk$ and outputs a blinded message $b$ and an unblinding factor $u$: $(b, u)
\gets \alg{Blind}(m, vk)$. The signing algorithm takes a signing key $sk$ and a
blinded message $b$ and outputs a blinded signature $s \gets \alg{Sign}(b, sk)$.
The unblinding algorithm takes a verification key $vk$, a blinded signature $s$
and an unblinding factor $u$ and outputs a signature $\sigma \gets
\alg{Unblind}(vk, s, u)$. The verification algorithm finally takes a
verification key $vk$, a message $m$ and a signature $\sigma$ and outputs a bit
$v \gets \alg{Verify}(vk, m, \sigma)$ that is 1 if the signature verifies.

A blind singature scheme in explicit form is correct if the following outputs $v
= 1$ for any message $m$, i.e. a correctly generated signature verifies:
\[
\begin{array}{l}
(sk, vk) \gets \alg{KeyGen}();\ 
(b, u) \gets \alg{Blind}(vk, m);\ 
s \gets \alg{Sign}(sk, b);\ \\
\sigma \gets \alg{Unblind}(vk, s, u);\ 
v \gets \alg{Verify}(vk, m, \sigma)
\end{array}
\]
\end{definition}

From the explicit form we can reconstruct the signer and user algorithms: the
signer algorithm receives a blinded message from the user, applies $\alg{Sign}$
with the signing key $sk$ and sends the result back to the user. The user
algorithm applies \alg{Blind} to the message, saves the unblinding factor $u$
and sends the blinded message $b$ to the signer; when the user algorithm gets a
value $s$ back from the signer it applies \alg{Unblind} using the saved factor
$u$ and outputs the resulting blind signature (to its caller, not the signer).

From this observation we could derive explicit forms of the the security games
for blind signatures in explicit form and check that the correctness conditions
in the two cases match up. The other way round is not possible in general as not
all blind signature schemes have an explicit form the way we defined it.

\subsubsection{Commitment schemes.}
A commitment scheme is the cryptographer's equivalent of placing a message in an
opaque envelope and placing this envelope on the table: no-one else can can read
your message until you open the envelope but you cannot change the message that
you have placed in the envelope either: you are committed to the message.

\begin{definition}
A commitment scheme $CS$ is a pair of algorithms
\[
CS = \left( \alg{Commit}, \alg{Open}\right)
\]
called the commitment and opening algorithm. The commitment algorithm takes a
message $m$ and returns a commitment $c$ and an opening key $k$: $(c, k) \gets
\alg{Commit}(m)$. The opening algorithm takes a message $m$, a commitment $c$
and a key $k$ and returns a bit $b$ to indicate whether the commitment matches
the message: $b \gets \alg{Open}(m, c, k)$. The opening algorithm must be
deterministic.

A commitment scheme must satisfy the following correctness property. For any
message $m$, if you run
\[
(c, k) \gets \alg{Commit}(m);\ b \gets \alg{Open}(m, c, k)
\]
then $b = 1$ i.e. correctly commited messages also open correctly.
\end{definition}

Security of commitment schemes has two parts. A commitment is hiding if you
cannot extract a committed message from a commitment until it is opened. A
commitment is binding if you cannot change it once committed.

In more detail, the hiding property says that for any two messages of your
choice, if you are given a commitment to one of them then you cannot guess
better than at random which message was committed to.

\begin{definition}
A commitment scheme $CS = (\alg{Commit}, \alg{Open})$ is hiding if no attacker
can win the following game with better probability than one half. If we consider
attackers with unbounded computation power, we can call a scheme perfectly
hiding; for attackers with reasonable (polynomially bounded) power we can call a
scheme computationally hiding.

\begin{description}
\item[Setup]
The game picks a bit $b$ at random.

\item[Moves]
The attacker may, once only, send a pair of messages $m_0, m_1$. The game runs
$(c, k) \gets \alg{Commit}(m_b)$ and returns $c$ to the attacker.

\item[Winning conditions]
The attacker wins if she guesses $b$. A guess stops the game.
\end{description}
\end{definition}

The binding property asks the attacker to produce one commitment $c$ and two
different messages $m, m'$ to which she can open the commitment, i.e. keys
$k, k'$ (which may or may not be the same) such that \alg{Open} returns 1 on
both triples involved.

\begin{definition}
A commitment scheme $CS = (\alg{Commit}, \alg{Open})$ is binding if no attacker
can win the following game. The same specialisation into perfectly and
computationally binding applies as for the hiding property.

\begin{description}
\item[Setup]
No setup.

\item[Moves]
No moves.

\item[Winning conditions]
The attacker may provide a string $c$, two messages $m, m'$ and two keys
$k, k'$. She wins if (1) $m \neq m'$ and (2) both $\alg{Open}(c, m, k)$ and
$\alg{Open}(c, m', k')$ return 1.
\end{description}
\end{definition}

\subsection{The FOO protocol}

The cryptographic tools we introduced above allow us to give the voting scheme
presented by Fujioka, Okamoto and Ohta at Auscrypt 1992 \cite{FOO92}. This
scheme was also the one that we motivated in the informal example above and has
the convenient abbreviation FOO.

The FOO protocol uses two administrators, a counter who publishes all ballots
sent to her and an authority who checks voters' elegibility and can produce
blind signatures. Voters must be able to talk anonymously to the counter; this
requirement could be achieved with cryptographic tools that we will introduce
later such as mix-nets.

The FOO protocol assumes that there is some public-key infrastructure in place
in which each voter has a digital signature keypair and the association of
verification keys to voters is public. FOO requires each voter to perform four
steps:
\begin{enumerate}
\item Prepare a ballot on her own, sign it and save a private random value.
\item Authenticate herself to the authority and get a blind signature on the ballot.
\item Submit the ballot and authority signature anonymously to a ballot counter (this is equivalent to publishing the ballot).
\item After voting has closed, submit the private random value from step 1 to the counter, also anonymously.
\end{enumerate}

\begin{definition}
The FOO protocol is the following protocol for voters, an authority and a counter.
\end{definition}

\begin{description}
\item[Tools] The FOO protocol requires a digital signature scheme $\Sigma$, a
blind signature scheme $BS$ with an explicit form and a commitment scheme $CS$.
We write algorithms with the scheme name as prefix, for example $BS.\alg{Sign}$,
to avoid ambiguity.

\item[Voter] The voter starts out with a digital signature keypair $(sk_V,
vk_V)$ for $\Sigma$, a vote $v$ and the authority's blind signature
verification key $vk_A$.
\begin{enumerate}
\item She creates a commitment $(c, k) \gets CS.\alg{Commit}(v)$, blinds it as
$(b, u) \gets BS.\alg{Blind}(vk_A, c)$ and signs this as $\sigma_V \gets
\Sigma.\alg{Sign}(sk_V, b)$.
\item She then sends $(ID_V, b, \sigma_V)$ to the authority and expects a
blinded signature $s$ in return. Here $ID_V$ is some string describing the
voter's identity.
\item On receipt of $s$, she creates the blind signature $\sigma_A \gets \alg{Unblind}(vk_A, s, u)$ and sends her ballot $(c, \sigma_A)$ anonymously to the counter. The counter replies with some random identifier $i$.
\item After voting has closed and the counter has invited the voters to open
their ballots, the voter sends $(i, v, k)$ anonymously to the counter.
\end{enumerate}

\item[Authority]
The authority has a keypair $(sk_A, vk_A)$ for a blind signature scheme. She
also has access to a table $T$ of the identities and verification keys of all
eligible voters: $(ID_V, vk_V)$ for all voters $V$.
Further, the authority has a list $L$ of the identities, blinded ballots
and signatures of all voters who have already voted (this list starts out empty
of course).
When a voter sends the authority a triple $(ID_V, b, \sigma_V)$ the
authority checks that the voter is eligible to vote, i.e. $ID_V \in T$, and retrieves the corresponding verification key $vk_V$.
The authority then checks that the signature is valid: $\Sigma.\alg{Verify}(vk_V, b, \sigma_V) = 1$. If this is correct, the authority checks that the voter has not already voted, i.e. $ID_V$ does not appear in $L$.
The authority then adds $(ID_V, b, \sigma_V)$ to $L$ and returns a blind
signature $s \gets BS.\alg{Sign}(sk_A, b)$ to the voter.

At the end of the voting phase, the authority publishes the list $L$.

\item[Counter]
The counter starts out with the authority's verification key $vk_A$.
The counter holds no secrets and performs no secret operations: the entire
protocol for the counter can be performed in public and therefore checked by
anyone.

During the voting phase, the counter anonymously receives ballots $(c, \sigma)$.
She checks that each incoming ballot is valid, i.e. $BS.\alg{Verify}(vk_A, c,
\sigma) = 1$ and publishes all accepted ballots along with their signatures and
a unique identifier $i$, i.e. the counter maintains a list of entries $(i, c,
\sigma)$. The identifiers could be randomly chosen or simply sequence numbers.

At the end of the election, the counter invites all voters to open their
ballots. On receipt of an anonymous message $(i, v, k)$ the counter retrieves
the entry $(i, c, \sigma)$ and if such an entry exists, she computes $x \gets
CS.\alg{Open}(v, c, k)$. If this returns $1$, the ballot is valid and the
counter adds the vote $v$ to the set of valid votes. Finally, the counter
tallies all valid votes.
\end{description}

\subsubsection{Verifiability of FOO.}

We will briefly show why FOO is a verifiable protocol. Specifically, we check
the following properties.

\begin{description}
\item[Individual verifiability] Voters can check that their ballot was counted.
\item[Universal verifiability] Anyone can check that all ballots were counted
 correctly.
\item[Ballot verifiability] Anyone can check that all ballots correspond to
 correct votes.
\item[Eligibility verifiability] Anyone can check that only eligible voters have
voted, and only once each.
\end{description}

For individual verifiability, since the counter just publishes all ballots the
voter can check if her ballot is included among the published ones. Better
still, in case of a dispute the voter can expose a cheating counter if the
counter refuses to accept a correctly signed ballot.

Universal verifiability is easy since the counter holds no secrets: anyone can
repeat the count of all opened ballots. The same holds for ballot verifiability
since the ballots are opened individually.

For eligiblility, first note that anyone can verify that only correctly signed
ballots are counted. If we assume that the authority is honest then only
eligible voters will receive a signature from the authority and only once each.
Even if the authority is dishonest, its log $L$ would show if it had ever blind-
signed a ballot that was not accompanied by a correct signature from a
legitimate voter key, or if the authority had signed two ballots with a
signature from the same voter.

\subsubsection{Dispute resolution in FOO.}

In addition to verifiability, the FOO protocol provides a digital audit trail
that can be used to resolve many disputes which could arise. We mention some
cases that were addressed in the original paper; we imagine that all these
disputes could be brought before a judge or election official.
In the following we assume that honest parties' keys are not available to
cheaters. This means that in any dispute between a honest and a dishonest party,
the honest party will be able to convince a judge that the other side is
cheating - more precisely, that either the other side is cheating or her
signature has been forged.
In the following we give a list of possible accusations and how a judge should
respond.

\begin{itemize}
\item The authority refuses to give a legitimate voter a signature, or provides
her with an invalid signature.

The voter can publish a blinded ballot and her digital signature on it;
a judge can now ask the authority to either sign this ballot or give a reason
for refusing to do so. If the judge asks to see the authority's blinded
signature, the voter can reveal her vote and blinding factor to the judge who
can then check the unblinding step and verify the resulting signature.
This way, a cheating authority will always be exposed.

\item The authority claims that a voter has already voted.

A judge can ask for the voter's previous blinded ballot and digital signature as
proof. If the authority fails to produce this, she is exposed - if she does
produce this, the voter must explain why said blinded ballot carries a signature
under her key.

\item The authority signs a ballot that does not come from a legitimate voter,
or more than one ballot from the same voter.

The judge checks the counter's published ballots against the authority's list
$L$ for any signed ballots that do not have a valid voter-signature in $L$, or
two ballots with the same voter's signature.

\item The authority signs something that is not a legitimate ballot.

If the illegitimate ballot is never opened, it does not contribute to the result
and can be ignored. Once a ballot is opened, the judge can check its contents.
It is not the authority's fault if its signature is discovered on an invalid
ballot: since the authority's signature is blind, the authority has no way of
knowing the contents of what it signs.

\item A voter tries to vote more than once.

The judge checks that all the counter's ballots are also referenced in the list
$L$ and then checks the list $L$ for two different ballots with the same voter's
signature.

\item The counter refuses to accept a legitimate ballot.

The judge checks the signature on the disputed ballot; if it verifies and the
counter still refuses then the counter is exposed as a cheater. The same applies
to opening keys $k$ where the judge checks using the opening algorithm.

\item The counter accepts an illegitimate ballot without a valid signature).

The judge checks the signature; if it fails the counter is exposed as a cheater.
The same applies to opening information.

\item The counter produces a false result.

The judge recomputes the result and disqualifies the counter if the results do
not match.
\end{itemize}

\section{Homomorphic Voting}

\subsection{Motivation and example}

\subsection{Asymmetric encryption}

\subsection{Minivoting}

\section{Privacy}

\begin{structure}
\begin{itemize}
\item bad ballots (solution: PoKs)
\item Cortier-Smyth attacks (solution: non-malleable ballots)
\item Trustee can decrypt individual ballots (solution: threshold)
\end{itemize}
\end{structure}

\subsection{Problems}

\subsection{Threshold encryption}

\section{Verifiability}

\section{Putting it all together}

% optional?
\section{Mix-nets}

\begin{thebibliography}{XXX11}
\bibitem[FOO92]{FOO92}
A. Fujioka, T. Okamoto and K. Ohta.
A Practical Secret Voting Scheme for Large Scale Elections.
In: ???

\bibitem[US11]{US11}
D. Schr\"oder and D. Unruh.
Security of Blind Signatures Revisited.
eprint, report 2011/316.

\end{thebibliography}

\end{document}

